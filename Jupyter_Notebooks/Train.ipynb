{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JW9Ej3Y9Uj8_"
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np; np.random.seed(42); import tensorflow as tf; tf.set_random_seed(42);\n",
    "import matplotlib.pyplot as plt; import pylab; import cv2;\n",
    "import os; from os import listdir; from os.path import isfile, join\n",
    "from Architecture import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hdTkx5rUj9Z"
   },
   "outputs": [],
   "source": [
    "# Image specifications\n",
    "img_height = 128; img_width = 128; img_channels = 3; batch_size = 1; rel_path = '...Path to this Jupyter Notebook...';\n",
    "\n",
    "# Define some placeholders\n",
    "with tf.name_scope(\"Placeholders\"):\n",
    "  \n",
    "    lr = tf.placeholder(tf.float32, shape = [], name = \"Learning_rate\");\n",
    "    train_mode = tf.placeholder(tf.bool, shape = [], name = \"BatchNorm_TrainMode\")\n",
    "    input_A = tf.placeholder(tf.float32, [batch_size, img_height, img_width, img_channels], name = \"Input_A\")\n",
    "    input_B = tf.placeholder(tf.float32, [batch_size, img_height, img_width, img_channels], name = \"Input_B\")\n",
    "    global_step = tf.Variable(0, name = \"global_step\", trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCc7YHczUj9e"
   },
   "outputs": [],
   "source": [
    "# Output of the generator which should ideally belong to target domain B in our case  \n",
    "with tf.variable_scope(\"Generator_\", reuse = False): \n",
    "    fake_img = generator_unet_128(input_A)\n",
    "    \n",
    "# Output of the discriminator which is probability of the real image being 1 \n",
    "with tf.variable_scope(\"Discriminator_\", reuse = False): \n",
    "    prob_real_img = discriminator_patch_gan(input_A, input_B)\n",
    "# Output of the discriminator which is probability of the fake image being 1\n",
    "with tf.variable_scope(\"Discriminator_\", reuse = True): \n",
    "    prob_fake_img = discriminator_patch_gan(input_A, fake_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tei6_KvrUj9i"
   },
   "outputs": [],
   "source": [
    "def LSGAN_loss():\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    g_loss: Generator_loss [minimizing the squared difference b/w prob_fake_img and 1]\n",
    "    d_loss: Discriminator_loss [minimizing the squared difference b/w prob_real_img & 1, and b/w prob_fake_img & 0]\n",
    "    \"\"\"\n",
    "\n",
    "    L1_weight = 200; L1_loss = tf.reduce_mean(tf.abs(input_B - fake_img))\n",
    "    g_loss = 0.5*tf.reduce_mean(tf.squared_difference(prob_fake_img, 1)) + L1_weight*L1_loss\n",
    "    d_loss = 0.5*tf.reduce_mean(tf.squared_difference(prob_real_img, 1)) + 0.5*tf.reduce_mean(tf.square(prob_fake_img))\n",
    "    \n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3kpheiHUj92"
   },
   "outputs": [],
   "source": [
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    \n",
    "    # Initialize an Adam optimizer with default beta2\n",
    "    optimizer = tf.train.AdamOptimizer(lr, beta1 = 0.5); model_vars = tf.trainable_variables()\n",
    "\n",
    "    # Seperate the variables corresponding to the discriminator and generator\n",
    "    d_vars = [var for var in model_vars if 'Discriminator_' in var.name]\n",
    "    g_vars = [var for var in model_vars if 'Generator_' in var.name]\n",
    "\n",
    "    g_loss, d_loss = LSGAN_loss();\n",
    "    # Define different optimizers for Discriminator and Generator\n",
    "    d_trainer = optimizer.minimize(d_loss, var_list = d_vars)\n",
    "    g_trainer = optimizer.minimize(g_loss, var_list = g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGg_dLA-Uj96"
   },
   "outputs": [],
   "source": [
    "def generate_fake_validation_images(sess, epoch):\n",
    "\n",
    "    \"\"\"\n",
    "    loc:        Path of the validation set\n",
    "    num_images: Number of the images in the validation set\n",
    "    \"\"\"\n",
    "    \n",
    "    loc = '...path to Validation set...'; \n",
    "    file_loc = [rel_path + loc + s for s in os.listdir(rel_path + loc)]\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices(tf.constant(file_loc))\n",
    "    val_dataset = val_dataset.map(lambda x: tf.subtract(tf.div(tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(x)), [img_height, img_width]), 127.5), 1))\n",
    "\n",
    "    val_iterator = val_dataset.make_one_shot_iterator(); next_element = val_iterator.get_next()\n",
    "    \n",
    "    if not os.path.exists(\"./Output/Validation/epoch_\" + str(epoch) + \"/\"):\n",
    "        os.makedirs(\"./Output/Validation/epoch_\" + str(epoch) + \"/\")\n",
    "    \n",
    "    for i in range(0, len(file_loc)):\n",
    "        \n",
    "        try:\n",
    "#           Get the next image\n",
    "            next_image = sess.run(validation_next_element)    \n",
    "#           next_image = np.expand_dims(cv2.cvtColor(next_image, cv2.COLOR_RGBA2RGB), axis = 0)\n",
    "\n",
    "#           Generate a fake image\n",
    "            fake_gen_img = sess.run(fake_img, feed_dict = {input_A: next_image})\n",
    "            \n",
    "#           Save the fake image at the specified location\n",
    "            plt.imsave(\"./Output/Validation/epoch_\" + str(epoch) + \"/img_\" + str(i) + \"_fake.png\",((fake_gen_img[0] + 1)*127.5).astype(np.uint8))\n",
    "            plt.imsave(\"./Output/Validation/epoch_\" + str(epoch) + \"/img_\" + str(i) + \".png\",((next_image[0] + 1)*127.5).astype(np.uint8))\n",
    "            \n",
    "        except tf.errors.OutOfRangeError: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific boolean to be set to True  \n",
    "Train = True; Test = False; Restore_and_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtSDaSoeUj-D"
   },
   "outputs": [],
   "source": [
    "def in_training_mode(num_epochs = 100, num_iters, log_dir = \"./checkpoints/\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    num_epochs: Number of epochs to train\n",
    "    log_dir:    Path where to save checkpoints\n",
    "    num_iters:  Number of training iterations in one epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Training Started\")\n",
    "    for epoch in range(sess.run(global_step), num_epochs):     \n",
    "\n",
    "        logs_dir = log_dir; d_l = 0; g_l = 0; num_iters = num_iters;\n",
    "        if not os.path.exists(logs_dir): os.makedirs(logs_dir)\n",
    "        sess.run(train_iterator.initializer)\n",
    "\n",
    "        if epoch < 20: curr_lr = 0.0002;\n",
    "        elif epoch % 20 == 0: curr_lr = curr_lr/2\n",
    "\n",
    "        for ptr in range(1, num_iters):\n",
    "            \n",
    "            try:\n",
    "#               Get the next element of the dataset  \n",
    "                a_next_image, b_next_image = sess.run(train_next_element)\n",
    "    \n",
    "#               a_next_image = np.expand_dims(cv2.cvtColor(a_next_image, cv2.COLOR_RGBA2RGB), axis = 0)   \n",
    "#               b_next_image = np.expand_dims(cv2.cvtColor(b_next_image, cv2.COLOR_RGBA2RGB), axis = 0)\n",
    "\n",
    "#               Run the train step to update the parameters of the discriminator with 4 times the curr_lr\n",
    "#               NOTE: This is done to avoid running multiple iterations of discriminator step as in the case of WGAN\n",
    "                _, dis_loss = sess.run([d_trainer, d_loss], feed_dict = {input_A: a_next_image, input_B: b_next_image, lr: curr_lr})   \n",
    "\n",
    "#               Run the train step to update the parameters of the generator with the curr_lr\n",
    "                _, gen_loss = sess.run([g_trainer, g_loss], feed_dict = {input_A: a_next_image, input_B: b_next_image, lr: curr_lr})\n",
    "\n",
    "#               Calculate the d_loss and g_loss\n",
    "                d_l += dis_loss; g_l += gen_loss\n",
    "\n",
    "#               Print some statistics\n",
    "                if(ptr % 10000 == 0):\n",
    "                    print(str(epoch*num_iters + ptr) + ' iterations completed and losses are:')\n",
    "                    print('Generator_loss_: ' + str(g_l/ptr)); print('Discriminator_loss_: ' + str(d_l/ptr))\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "#               Initialize the iterator again\n",
    "                sess.run(training_iterator.initializer); continue;\n",
    "\n",
    "#       Generate fake validation images at the end of each epoch only to check the progress of the model\n",
    "        generate_fake_validation_images(sess, epoch)\n",
    "        \n",
    "#       Save the checkpoints\n",
    "        saver.save(sess, logs_dir + 'composites', global_step = global_step)\n",
    "#       Increment the global variable\n",
    "        sess.run(tf.assign(global_step, epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNYBWKkCUj-H"
   },
   "outputs": [],
   "source": [
    "if Train:\n",
    "    \n",
    "    \"\"\"\n",
    "    num_epochs: number of epochs to run\n",
    "    \"\"\"\n",
    "\n",
    "    # Sorting the filename wrt unique indices of each image\n",
    "    def sort_composite_filename(x): return int(x[4:-4])\n",
    "\n",
    "    # Create a datset of composites\n",
    "    comp_dir = '/images/Composite/';\n",
    "    comp_fileloc = [rel_path + comp_dir + s for s in sorted(os.listdir(rel_path + comp_dir), key = sort_composite_filename)]\n",
    "    comp_dataset = tf.data.Dataset.from_tensor_slices(tf.constant(comp_fileloc));\n",
    "    comp_dataset = comp_dataset.map(lambda x: tf.subtract(tf.div(tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(x)), [img_height, img_width]), 127.5), 1))\n",
    "\n",
    "    # Sorting the filename wrt unique indices of each image\n",
    "    def sort_natural_filename(x): return int(x[4:-4])\n",
    "\n",
    "    # Create a datset of natural images\n",
    "    nat_dir = '/images/Natural/'\n",
    "    nat_fileloc = [rel_path + nat_dir + s for s in sorted(os.listdir(rel_path + nat_dir), key = sort_natural_filename)]\n",
    "    nat_dataset = tf.data.Dataset.from_tensor_slices(tf.constant(nat_fileloc));\n",
    "    nat_dataset = nat_dataset.map(lambda x: tf.subtract(tf.div(tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(x)), [img_height, img_width]), 127.5), 1))\n",
    "\n",
    "    # Create a final dataset by zipping the above two [in order to ensure that composite and its ground truth are together]\n",
    "    train_dataset = tf.data.Dataset.zip((comp_dataset, nat_dataset)).shuffle(2000).repeat()\n",
    "    train_dataset = (train_dataset.batch(batch_size)).prefetch(10);\n",
    "\n",
    "    # Create an interator over the dataset \n",
    "    train_iterator = train_dataset.make_initializable_iterator(); train_next_element = train_iterator.get_next()\n",
    "    \n",
    "    # Set the gpu config options\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.9)\n",
    "    sess = tf.Session(config = tf.ConfigProto(gpu_options = gpu_options))\n",
    "    \n",
    "    # Initialize the global variables\n",
    "    sess.run(tf.global_variables_initializer()); saver = tf.train.Saver(max_to_keep = 10)\n",
    "    \n",
    "    in_training_mode(100, len(nat_fileloc));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Restore_and_train:\n",
    "    \n",
    "    \"\"\"\n",
    "    num_epochs: number of epochs to run\n",
    "    \"\"\"\n",
    "    \n",
    "#   Set the gpu config options\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.9)\n",
    "    sess = tf.Session(config = tf.ConfigProto(gpu_options = gpu_options))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#   Load the model with the latest checkpoints\n",
    "    saver = tf.train.Saver(max_to_keep = 10)\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./checkpoints/ls_pix2pix/'))\n",
    "    print ('Loaded checkpoint! Training from last checkpoint started !!')\n",
    "    \n",
    "#   Train it again for n number of epochs\n",
    "    in_training_mode(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Test:\n",
    "    \n",
    "#   Set the config options\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.9)\n",
    "    sess = tf.Session(config = tf.ConfigProto(gpu_options = gpu_options))\n",
    "    sess.run(tf.global_variables_initializer()); saver = tf.train.Saver()\n",
    "    \n",
    "#   Load the model with the latest checkpoints\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./checkpoints/ls_pix2pix/'))\n",
    "    print ('Loaded checkpoint! Generating fake images corresponding to Test Composites!!')\n",
    "      \n",
    "#   Evaluate it on test set  \n",
    "    loc = '...path to Test set...';\n",
    "    file_loc = [rel_path + loc + s for s in os.listdir(rel_path + loc)]\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(tf.constant(file_loc))\n",
    "    test_dataset = test_dataset.map(lambda x: tf.subtract(tf.div(tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(x)), [img_height, img_width]), 127.5), 1))\n",
    "\n",
    "#   Initialize the test iterator\n",
    "    test_iterator = test_dataset.make_one_shot_iterator(); test_next_element = test_iterator.get_next()\n",
    "    \n",
    "#   Make the directory if it doesn't exists\n",
    "    if not os.path.exists(\"./Output/Test/\"): os.makedirs(\"./Output/Test/\")\n",
    "    \n",
    "#   Set the number of test images in test folder!!\n",
    "    num_images = 10; \n",
    "    for i in range(0, num_images):\n",
    "        \n",
    "        try:\n",
    "#           Get the next element\n",
    "            next_image = sess.run(test_next_element)\n",
    "#           next_image = np.expand_dims(cv2.cvtColor(next_image, cv2.COLOR_RGBA2RGB), axis = 0)\n",
    "            \n",
    "#           Generate the fake image\n",
    "            fake_gen_img = sess.run(fake_img, feed_dict = {input_A: next_image})\n",
    "            \n",
    "#           Save the image at specified location\n",
    "            plt.imsave(\"./Output/Test/fake_img_\" + str(i) + \".png\",((fake_gen_img[0] + 1)*127.5).astype(np.uint8))\n",
    "            plt.imsave(\"./Output/Test/img_\" + str(i) + \".png\",((next_image[0] + 1)*127.5).astype(np.uint8))\n",
    "            \n",
    "        except tf.errors.OutOfRangeError: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Train_Function",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
