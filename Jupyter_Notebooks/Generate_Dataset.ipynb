{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; import skimage; import scipy; import skimage.io; import skimage.io as io; \n",
    "import matplotlib.pyplot as plt; from PIL import Image, ImageEnhance; from skimage import img_as_ubyte;\n",
    "import scipy.optimize; import cv2; import os; from pycocotools.coco import COCO; \n",
    "import warnings; warnings.filterwarnings(\"ignore\");\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Kelvin table is taken from link: http://www.andi-siess.de/portfolio/rgb-to-color-temperature\n",
    "\n",
    "kelvin_table = {\n",
    "    1600: (255, 115, 0),   1700: (255, 121, 0),   1800: (255, 126, 0),   1900: (255, 131, 0),   2000: (255, 138, 18), \n",
    "    2100: (255, 142, 33),  2200: (255, 147, 44),  2300: (255, 152, 54),  2400: (255, 157, 63),  2500: (255, 161, 72), \n",
    "    2600: (255, 165, 79),  2700: (255, 169, 87),  2800: (255, 173, 94),  2900: (255, 177, 101), 3000: (255, 180, 107), \n",
    "    3100: (255, 184, 114), 3200: (255, 187, 120), 3300: (255, 190, 126), 3400: (255, 193, 132), 3500: (255, 196, 137),\n",
    "    3600: (255, 199, 143), 3700: (255, 201, 148), 3800: (255, 204, 153), 3900: (255, 206, 159), 4000: (255, 209, 163),\n",
    "    4100: (255, 211, 168), 4200: (255, 213, 173), 4300: (255, 215, 177), 4400: (255, 217, 182), 4500: (255, 219, 186),\n",
    "    4600: (255, 221, 190), 4700: (255, 223, 194), 4800: (255, 225, 198), 4900: (255, 227, 202)}\n",
    "\n",
    "def change_temp_img(image, temp):\n",
    "\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    image:     Original Image\n",
    "    temp:      temperature of the image (should be in between 1600 and 4900)\n",
    "\n",
    "    Returns:\n",
    "    mod_image: Modified image\n",
    "    \"\"\"\n",
    " \n",
    "    r, g, b = kelvin_table[temp];\n",
    "    \n",
    "#   Convert the image into array\n",
    "    image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "    matrix = ( r/255., 0., 0., 0., 0., g/255., 0., 0., 0., 0., b/255.0, 0.)\n",
    "    mod_img = np.uint8(image.convert('RGB', matrix))\n",
    "    \n",
    "    return mod_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_val(a, b, c, d):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    a, b, c, d: Integers\n",
    "    \n",
    "    Returns:\n",
    "    A random integer in between a and b or c and d depending on threshold, calculated as below\n",
    "    \"\"\"\n",
    "    \n",
    "    delta_1 = b-a; delta_2 = d-c;\n",
    "    \n",
    "    if(np.random.rand() < delta_1/(delta_1 + delta_2)):\n",
    "        return np.random.uniform(a, b)\n",
    "    else:\n",
    "        return np.random.uniform(c, d)\n",
    "    \n",
    "    \n",
    "def apply_transformation_1(img, mask, img_backgnd):\n",
    "\n",
    "    \"\"\"\n",
    "    Randomly perturb the contrast, brightness and color of a specific image!\n",
    "    \n",
    "    img:         Original image\n",
    "    mask:        mask of the relevant subject to be extracted from the image\n",
    "    img_backgnd: background of the image\n",
    "    \n",
    "    Returns: \n",
    "    img:         Modified version of the image with the random distortions!\n",
    "    \"\"\"\n",
    "    \n",
    "#   Selecting a random integer in the specified range \n",
    "    ind = get_random_val(0.6, 0.9, 1.1, 1.5); \n",
    "#   Randomly change the brightness of the image\n",
    "    img = Image.fromarray(img.astype('uint8'), 'RGB');\n",
    "    obj = ImageEnhance.Brightness(img); img = obj.enhance(ind);\n",
    "    img = img*np.expand_dims(mask, axis = 2) + img_backgnd;\n",
    "    \n",
    "    ind = get_random_val(0.6, 0.9, 1.1, 1.7);\n",
    "#   Randomly change the color of the image\n",
    "    img = Image.fromarray(img.astype('uint8'), 'RGB');\n",
    "    obj = ImageEnhance.Color(img); img = obj.enhance(ind);\n",
    "    img = img*np.expand_dims(mask, axis = 2) + img_backgnd;\n",
    "    \n",
    "    ind = get_random_val(0.6, 0.9, 1.1, 1.7);\n",
    "#   Randomly change the contrast of the image\n",
    "    img = Image.fromarray(img.astype('uint8'), 'RGB');\n",
    "    obj = ImageEnhance.Contrast(img); img = obj.enhance(ind);\n",
    "    img = img*np.expand_dims(mask, axis = 2) + img_backgnd;\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_transfer_processing(image):\n",
    "\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    image:     Input_image\n",
    "    \n",
    "    Returns:\n",
    "    image_lab: Input_image with the modified L component \n",
    "    \"\"\"\n",
    "    \n",
    "#   To effectively stylize images with global transforms, we first compress the dynamic ranges of the two images\n",
    "#   using a γ (= 2.2) mapping and convert the images into the LAB colorspace\n",
    "\n",
    "    gamma = 2.2; clip_percent = 0.005; image = skimage.exposure.adjust_gamma(image, gamma = gamma);\n",
    "    image_lab = skimage.color.rgb2lab(image); image_lum = image_lab[:, :, 0]\n",
    "\n",
    "#   Then, we stretch the luminance (L channel) to cover the full dynamic range after clipping both the minimum and\n",
    "#   the maximum 0.5 percent pixels of luminance levels\n",
    "\n",
    "    image_lum_flat = image_lum.ravel().copy(); image_lum_sorted = image_lum_flat.argsort()\n",
    "    lum_cut_pos = int(image_lum_flat.size * clip_percent); \n",
    "    \n",
    "    lum_min = image_lum_flat[image_lum_sorted[lum_cut_pos]];\n",
    "    lum_max = image_lum_flat[image_lum_sorted[image_lum_sorted.size - lum_cut_pos]];\n",
    "    image_lum[image_lum < lum_min] = lum_min; image_lum[image_lum > lum_max] = lum_max;\n",
    "\n",
    "    image_lab[:, :, 0] = (image_lum - lum_min) / (lum_max - lum_min) * 100;\n",
    "    \n",
    "    return image_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ravel_xy_dim(image): return image.reshape(image.shape[0] * image.shape[1], 3);\n",
    "\n",
    "def get_linear_transformation(img_1_sigma, img_2_sigma):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    img_1_sigma: Covariance matrix of the Content image\n",
    "    img_2_sigma: Covariance matrix of the Style image\n",
    "    \n",
    "    Returns:\n",
    "    linear_transformation_fn: Linear transformation function\n",
    "    \"\"\"\n",
    "\n",
    "#   The solution is unstable for low input covariance values, leading to color artifacts when the input has low \n",
    "#   color variation. To avoid this, regularize the solution by clipping diagonal elements of Σ_img as:\n",
    "#   Σ_img = max(Σ_img , λr*I)\n",
    "\n",
    "    lambda_r = 7.5; img_1_sigma = np.maximum(img_1_sigma, np.eye(img_1_sigma.shape[0]) * lambda_r);\n",
    "    \n",
    "    inv_sqrt_img_1_sigm = np.matrix(scipy.linalg.fractional_matrix_power(img_1_sigma, -0.5));\n",
    "    sqrt_img_1_sigma    = np.matrix(scipy.linalg.fractional_matrix_power(img_1_sigma,  0.5));\n",
    "    affine_matrix       = sqrt_img_1_sigma * np.matrix(img_2_sigma) * sqrt_img_1_sigma;\n",
    "    sqrt_affine_matrix  = np.matrix(scipy.linalg.fractional_matrix_power(affine_matrix, 0.5));\n",
    "    \n",
    "#   T = [(Σ_img)**−1/2] * [[(Σ_img)**1/2] * Σ_smp * [(Σ_img)**1/2]]**0.5 * [(Σ_img)**−1/2]\n",
    "    \n",
    "    linear_transformation_fn =  inv_sqrt_img_1_sigm * sqrt_affine_matrix * inv_sqrt_img_1_sigm;\n",
    "    \n",
    "    return linear_transformation_fn\n",
    "    \n",
    "def color_transfer_processing(image_1, image_2, mask_1 = None, mask_2 = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    image_1: Content image\n",
    "    image_2: Style image\n",
    "    \n",
    "    Returns:\n",
    "    linear_transformation_fn: Linear transformation function\n",
    "    \"\"\"\n",
    "    \n",
    "    image_1_copy = image_1.copy(); image_2_copy = image_2.copy();\n",
    "    \n",
    "    if masked_color_transfer:\n",
    "        mask_1  = mask_1[:, :, None]*np.ones(3)[None, None, :]; mask_2 = mask_2[:, :, None]*np.ones(3)[None, None, :];\n",
    "        image_1 = np.ma.masked_array(image_1, 1 - mask_1); image_2 = np.ma.masked_array(image_2, 1 - mask_2);\n",
    "        \n",
    "#   Covert the image into 2-dimensional vector (rolling along the spatial dimesnions)\n",
    "    img_1_reshaped = ravel_xy_dim(image_1);  img_2_reshaped = ravel_xy_dim(image_2);\n",
    "    \n",
    "#   Calculate the covariance matrix (3-dimensional)\n",
    "    img_1_sigma = np.ma.cov(img_1_reshaped.transpose()); img_2_sigma = np.ma.cov(img_2_reshaped.transpose());\n",
    "    t = get_linear_transformation(img_1_sigma, img_2_sigma);\n",
    "    \n",
    "#   Both images can be of different size!!\n",
    "    img_1_mu = np.ma.mean(img_1_reshaped, axis = 0); img_2_mu = np.ma.mean(img_2_reshaped, axis = 0);\n",
    "    xr = (ravel_xy_dim(image_1_copy) - img_1_mu).dot(t) + img_2_mu; \n",
    "\n",
    "    return np.array(xr).reshape(image_1_copy.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lum_transfer_function(lum_image, param):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    lum_image: L channel of the original image\n",
    "    param:     Parameters to be optimized\n",
    "    \n",
    "    Returns:\n",
    "    num / den: Transfer function\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp = np.arctan(param[0] / param[1]); \n",
    "    num = tmp + np.arctan((lum_image - param[0]) / param[1]); den = tmp + np.arctan((1 - param[0]) / param[1])\n",
    "\n",
    "    return  num / den;\n",
    "\n",
    "def get_lum_cost(param, lum_image, lum_cal):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    lum_input: L channel of the original image\n",
    "    param:     L calculated\n",
    "    \n",
    "    Returns:\n",
    "    num / den: squared L2 norm of the || g(lum_input) − lum_cal ||, g is transfer function\n",
    "    \"\"\"\n",
    "    return np.power(np.linalg.norm(get_lum_transfer_function(lum_image, param) - lum_cal, 2), 2);\n",
    "\n",
    "def extract_lum_feature(image, bins = 99, num_of_samples = 32):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    image: Input image\n",
    "    bins:  Total bins in which to categorize the pixel intensities\n",
    "    num_of_samples: # uniformly sampled percentiles of the luminance cumulative distribution function\n",
    "    \n",
    "    Returns:\n",
    "    bins[index]: Luminance values at the percentiles calculated from above.\n",
    "    \"\"\"\n",
    "    \n",
    "    hist, bins = np.histogram(image.ravel(), bins = bins, range = (1, 100), normed = True); cdf = np.cumsum(hist); \n",
    "    percents = np.arange(1, 1 + num_of_samples) / num_of_samples; index = np.searchsorted(cdf, percents);\n",
    "    \n",
    "    return bins[index]\n",
    "\n",
    "def luminance_transfer_processing(image_1, image_2, image_result):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    image_1:        Content image\n",
    "    image_2:        Style image\n",
    "    image_result:   Final image\n",
    "    \n",
    "    Returns:\n",
    "    image_result:   Final image\n",
    "    \"\"\"\n",
    "    \n",
    "    tau = 0.4; num_of_samples = 32;\n",
    "\n",
    "    lum_img_1 = extract_lum_feature(image_1[:, :, 0], num_of_samples = num_of_samples)\n",
    "    lum_img_2 = extract_lum_feature(image_2[:, :, 0], num_of_samples = num_of_samples)\n",
    "    lum_cal = lum_img_1 + (lum_img_2 - lum_img_1)*(tau / np.minimum(tau, np.linalg.norm(lum_img_2 - lum_img_1, np.inf)))\n",
    "\n",
    "    target_function = lambda para: get_lum_cost(para, lum_img_1, lum_cal)\n",
    "    result = scipy.optimize.minimize(target_function, np.random.random_sample([2]));\n",
    "    image_result[:, :, 0] = get_lum_transfer_function(image_result[:, :, 0], result.x)\n",
    "    \n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation_2(img_1 = None, mask_1 = None, img_1_backgnd = None, img_2 = None, mask_2 = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    img_1:         Content image\n",
    "    mask_1:        Mask of the random subject to be extracted from the image\n",
    "    img_backgnd_1: Background of the Original image\n",
    "    img_2:         Randomly picked another image (acts like a Stylized image)\n",
    "    mask_2:        Mask of the Stylized image\n",
    "    \n",
    "    Returns: \n",
    "    final_image:   Perturbed version of the Original image!\n",
    "    \"\"\"\n",
    "    \n",
    "    image_inp = pre_transfer_processing(skimage.img_as_float(img_1));\n",
    "    image_smp = pre_transfer_processing(skimage.img_as_float(img_2));\n",
    "    \n",
    "    if masked_color_transfer: final_image = color_transfer_processing(image_inp, image_smp, mask_1, mask_2);\n",
    "    else: final_image = color_transfer_processing(image_inp, image_smp);\n",
    "    \n",
    "    if luminance_transfer: final_image = luminance_transfer_processing(image_inp, image_smp, final_image);\n",
    "        \n",
    "    final_image = skimage.color.lab2rgb(final_image); \n",
    "    final_image = img_as_ubyte(skimage.exposure.adjust_gamma(final_image, gamma = 1 / 2.2));\n",
    "    final_image = final_image*np.expand_dims(mask_1, axis = 2) + img_1_backgnd;\n",
    "    \n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cat = ['person']; relevant_cat_img_count = [0]*len(relevant_cat); \n",
    "\n",
    "def get_img(bool_orig_img = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns: \n",
    "    img:  image with the relevant category in it\n",
    "    anns: annotations of the image\n",
    "    \"\"\"\n",
    "    \n",
    "    ind = np.random.randint(0, len(relevant_cat));\n",
    "    catIds = coco.getCatIds(catNms = relevant_cat[ind]); imgIds = coco.getImgIds(catIds = catIds);\n",
    "    \n",
    "    if bool_orig_img: relevant_cat_img_count[ind] += 1; img = coco.loadImgs(imgIds[relevant_cat_img_count[ind]])[0];\n",
    "    else: img = coco.loadImgs(imgIds[np.random.randint(low = 0, high = len(imgIds))])[0];\n",
    "\n",
    "    I = io.imread('%s/%s/%s'%(dataDir, dataType, img['file_name']))\n",
    "    annIds = coco.getAnnIds(imgIds = img['id'], catIds = catIds, iscrowd = 0, areaRng = [15000, 50000000])\n",
    "    anns = coco.loadAnns(annIds);\n",
    "\n",
    "    return I, anns\n",
    "\n",
    "def GetImg_Foregnd_Backgnd(image, anns):\n",
    "  \n",
    "    \"\"\"\n",
    "    Arguments: \n",
    "    image: Original image\n",
    "    anns:  Annotations of the corresponding image\n",
    "    \n",
    "    Returns: \n",
    "    Img_Foregnd: image foreground\n",
    "    Img_Backgnd: image background\n",
    "    mask:        mask of the image\n",
    "    ind:         random index used while selecting the one of the subjects\n",
    "    \"\"\"\n",
    "    \n",
    "    ind = np.random.randint(0, len(anns)) ; mask = COCO.annToMask(coco, anns[0])\n",
    "    img_foregnd = image*np.expand_dims(mask, axis = 2); img_backgnd = image - img_foregnd\n",
    "    \n",
    "    return img_foregnd, img_backgnd, mask, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fakeimg():\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "    Returns: None\n",
    "    Save the original image, mask of the image, and modified version of the image at the specified location\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(0, 50000):\n",
    "        \n",
    "        while(True):\n",
    "            img_1, ann_1 = get_img(bool_orig_img = True);\n",
    "            if(len(ann_1) == 0 or len(img_1.shape) < 3): continue\n",
    "            else: break;\n",
    "        \n",
    "#       Task dependent (here, I am sampling another image from the original COCO Dataset, if your stylized images \n",
    "#       are coming from another datset; then modify the following 3 lines of code)\n",
    "\n",
    "        while(True):\n",
    "            img_2, ann_2 = get_img(bool_orig_img = False);\n",
    "            if(len(ann_2) == 0 or len(img_2.shape) < 3): continue\n",
    "            else: break;\n",
    "                \n",
    "        img_1_foregnd, img_1_backgnd, mask_1, ind_1 = GetImg_Foregnd_Backgnd(img_1, ann_1);\n",
    "        if masked_color_transfer: _, _, mask_2, _ = GetImg_Foregnd_Backgnd(img_2, ann_2);\n",
    "        else: mask_2 = None\n",
    "        \n",
    "        mod_img_1 = apply_transformation_1(img_1, mask_1, img_1_backgnd);\n",
    "        mod_img_2 = apply_transformation_2(img_1, mask_1, img_1_backgnd, img_2, mask_2);\n",
    "        \n",
    "        file_loc = [\"./Natural/\", \"./Mask/\", \"./Composite_1/\", \"./Composite_2/\"]\n",
    "        for file in file_loc: \n",
    "            if not os.path.exists(file): os.makedirs(file);\n",
    "              \n",
    "        plt.imsave(fname = './Natural/img_'     + str(i) + '.jpg', arr = img_1)\n",
    "        plt.imsave(fname = './Mask/img_'        + str(i) + '_mask.jpg', arr = mask_1)\n",
    "        plt.imsave(fname = './Composite_1/img_' + str(i) + '.jpg', arr = mod_img_1)\n",
    "        plt.imsave(fname = './Composite_2/img_' + str(i) + '.jpg', arr = mod_img_2)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = './'; dataType = 'train2014'; annFile = '%s/annotations/instances_%s.json'%(dataDir, dataType)\n",
    "\n",
    "coco = COCO(annFile); cats = coco.loadCats(coco.getCatIds())\n",
    "\n",
    "print(\"\\n\"); categories = [cat['name'] for cat in cats]\n",
    "print ('COCO categories:\\n', ' '.join(categories))\n",
    "\n",
    "print(\"\\n\"); supercategories = set([cat['supercategory'] for cat in cats])\n",
    "print ('COCO supercategories:\\n', ' '.join(supercategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "masked_color_transfer = False; luminance_transfer = False; get_fakeimg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
